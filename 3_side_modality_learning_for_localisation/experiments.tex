\section{Long-term localization}
\label{sec:experiments}

As a first step, we conduct preliminary experiments to justify design choices for our method. Then, in the second part of this section, we compare the localization performances of the proposed image descriptors.

\subsection{Preliminary results}

\subsubsection{Contribution of the depth information}
\input{3_side_modality_learning_for_localisation/tabs/depth_eval}
In this paragraph, we investigate the impact on localization performances provided by the side geometric information on our method. For a consistent comparison in terms of number of trainable parameters, we introduce RGB$^+$ network that has the same architecture as our proposed method. We train RGB$^+$ with images only to compare the localization results against our method that uses side depth information. For training RGB$^+$, we simply remove the pixel loss introduced in equation~(\ref{eq:l1_loss}), and make the weights of the decoder $D_a$ trainable when optimizing triplets losses constraints. Results on the validation dataset with encoder architecture Alexnet and decoder \ac{mac} are presented in table~\ref{tab/eval_depth}.

Increasing the size of the system results in a better localization (RGB$^{+}$ + MAC $>$ RGB + MAC). However, our RGB(D) + MAC system always produces higher localization results facing RGB$^{+}$ + MAC, which shows that the side depth information provided during training is wisely used to create the final description.

\subsubsection{Descriptor comparison}
\input{3_side_modality_learning_for_localisation/figures/experiments/netvlad_mac}
In figure~\ref{fig:netvlad_vs_mac}, we present the localization scores of the three different methods on the validation set with Alexnet as backbone encoder. It clearly demonstrates the superiority of the NetVLAD pooling layer compared to the MAC descriptor in term of precision (recall@D). As we are more focus on precision than on recall, our concern is about localization, we only use NetVLAD as pooling layer for the rest of the experiments (in combination with Alexnet or Resnet encoder). Still, this preliminary experiment has shown that the proposed method can be used in combination with various descriptor pooling layers.

\input{3_side_modality_learning_for_localisation/figures/experiments/oxford_cmu_res}
\input{3_side_modality_learning_for_localisation/figures/experiments/im_exs}
\subsection{Localization results}
\label{subsec:results}

Localization results on the six query sets are presented in figure~\ref{fig:results}. We also show, in figure~\ref{fig:im_exs} ($3^{rd}$, $5^{th}$ and $6^{th}$ columns), some examples of top-1 returned candidate by the different descriptors. Both methods trained with auxiliary depth information (hallucination RGB(H) and our RGB(D)) perform on average better than the RGB baseline. This confirm our intuition:  geometric clues given during the training process can be efficiently used for \ac{cbir} for localization. In addition to that, compared to hallucination network, our method shows better results, both in terms of recall and precision. We report results for the hallucination network only with encoder Alexnet as we were not able to obtain stable training when using a deeper architecture.

We obtain convincing localization results for the CMU query sets (figure~\ref{fig:results} d-f). It means that our method is able to generalize well on unseen architectural structures for the depth map creation and the extraction of discriminative clue for localization.

Our method shows the best localization improvement on the Oxford - Snow query sets (figure~\ref{fig:results}-b) and CMU -- Snow (for encoder Alexnet, see figure~\ref{fig:results}-e). Standard image descriptors are confused by local changes caused by the snow on the scene whereas our descriptor remains confident by reconstructing the geometric structure of the scene (see figure~\ref{fig:im_exs}, CMU-Snow 1$^{st}$ row). Similar results should be intended regarding Oxford -- Night query set (figure~\ref{fig:results}-c), however, none of the tested methods are able to perform on this particular scenario. In the following section, we investigate why our method has failed on the night to day localization task.

