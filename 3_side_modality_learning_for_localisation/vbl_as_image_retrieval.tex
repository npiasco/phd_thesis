\section{\Ac{vbl} as image retrieval}

\subsection{Learned global image descriptor.}
\label{subsec:cnn_as_global_desc}
Table~\ref{tab:cnn_details} presents main \ac{cnn} architectures involved in \ac{vbl}. Firstly, \ac{cnn} have been used for the task of localization without special training, exploiting inherent domain transfer capability of neural network. It is also interesting to notice that the most discriminative descriptors for the task of image-retrieval are extracted from mid-level convolutional layers instead of fully-connected layers~\citep{Babenko2014,Sunderhauf2015}.

In recent works~\citep{Arandjelovic2017,Radenovic2016, Gordo2016}, authors tackle the problem of fine tuning a pre-trained network for the specific task of similar images association. \citet{Arandjelovic2017} introduce a weakly supervised triplet ranking loss, feeding the network with positive and negative examples before applying the back-propagation. Positive examples are candidates related to a query image and negative examples are non-relevant candidates. Works in~\citep{Radenovic2016, Gordo2016} use a different approach: two~\citep{Radenovic2016} or three~\citep{Gordo2016} identical networks receive negative and/or positive examples at each iteration, and the back-propagation is operated on the different networks. By sharing the weights between the different networks and by applying a relevant common loss, the system can learn a data representation suitable for similarity research.	Authors insist on the need of having a clear and large database. Therefore, works from~\citep{Radenovic2016, Gordo2016} introduce novel methods to automatically reject wrong images, cluster the data into similarity groups and associated positive images with hard negative samples (\textit{e.g.} very dissimilar images) for training. The Time Machine functionality of Google Street-View is used in~\citep{Arandjelovic2017} to gather a large database composed of the same places at different periods of time. Data synthesis by view rendering is also performed for gathering large amount of data~\citep{Jia2016,Sizikova2016}.  Pre-treatment on training data are more generally used with learning-based methods~\citep{Kim2015,Cao2013}. 

Further explanations regarding \ac{cnn} and specially aggregation methods performed inside the network can be found in the next section~\S\ref{subsubsec:cnn_aggregation}.

\subsection{Features Aggregation}
\label{subsec:features_aggregation}
The similarity search can be computationally expensive when the data is described by a large descriptor, i.e. a vector of high dimension. Particularly, local features (\S\ref{subsec:local_feature}) are prompt to produce a large number of descriptors for each single data. Features aggregation is then performed in order to reduce the dimensionality of the descriptor vector. In \ac{vbl}, the aggregation process emphasize specific features that are more beneficial for the localization task.

\paragraph{Quantization}
Quantization methods have been widely adopted in image-retrieval domain since pioneer contribution of \citet{Sivic2003}. They consider the problem of object retrieval in an image described through local features in the same manner as text document research. Words equivalent in image domain becomes local features and a dictionary is build upon a large set of features extracted from visual documents' database. These features are clustered to reduce the size of the dictionary; clusters' centroids are then called visual words. For each visual word in the dictionary, and inverted file is maintained to efficiently retrieve all the data that present this specific visual word. The bag of features (BoF) associates a vector of the dimension of the dictionary containing the visual word frequency of a specific visual document. With this representation, data similarity can be efficiently computed by a simple inner product of their respective visual word frequency vector.

\begin{description}
	\item[Feature to visual word assignment.] BoF original scheme~\citep{Sivic2003} proceeds to a hard assignment from the extracted feature to the nearest visual word in the dictionary. However, depending on where the feature lies inside the Voronoi cell created in the clustering step, hard assignment can deteriorate the representation of the visual document. Soft assignment~\citep{Philbin2008} methods have been considered by associating the feature according to a linear combination of the $k$ nearest visual words. Hamming embedding (HE), introduced by \citet{Jegou2008}, subdivides Voronoi cells and associates to each feature a binary signature to refine its position in the visual vocabulary. This method leads to excellent result in term of accuracy and rapidity and is still used in state-of-the-art \ac{vbl}~\cite{Arandjelovic2014}. Inspired by Fisher Vectors (FV) formulation~\citep{Perronnin2010}, \citet{Jegou2012} introduce Vector of Locally Aggregated Descriptors (VLAD) representation for image-based retrieval. The difference between feature and its closest visual word is assigned to the final descriptor, instead of the visual word itself. The underlying idea behind VLAD representation have inspired various \ac{vbl} methods~\citep{Kim2015,Torii2015,Arandjelovic2017,Yan2016}. For instance, \citet{Kim2015} introduce PBVLAD method to locally fuse SIFT features detected inside a MSER blob. Novel features aggregation method have been recently presented in~\citep{Jegou2014}.
	
	\item[Weighting scheme.] The weighting step is supposed to emphasize discriminative features regarding the similarity comparison.	Original method by \citep{Sivic2003} used \textit{tf-idf} weighting, relying on the occurrence frequency of the features in the database. \citet{Jegou2009} handle the problem of intra and inter burstiness of visual words (i.e. the fact that a feature is more likely to appear in an image if it has already been detected once) by adapting the weight of the visual words before (inter-burstiness) and during (intra-burstiness) the query process. \citet{Torii2013} tackle the problem of visual burstiness introduced by repetitive structures (abundant in urban environment) and introduce meta-features encompassing several similar descriptors (comparable both in their descriptor vector and their spatial location in the image). Such improvement permits a dense extraction of local features in images, bringing superior result in urban environment \ac{vbl}~\citep{Qu2016,Torii2015}. Another work from \citet{Morago2016} that exploits the redundancy present in buildings facades. Recently, \citet{Arandjelovic2014} improve \textit{tf-idf} scheme by considering the descriptors' density in feature space. With their DisLoc weighing, 7\% of the less discriminative visual words can be removed from the database without impacting the performances of the similarity computation. \citet{Mousavian2015} introduce semantic knowledge in the local feature weighting process, reducing the impact of features associated with non-relevant elements for localization (i.e. elements that are likely to change or disappear, such as trees and cars).
\end{description}

\paragraph{Aggregation in CNN}
\input{3_side_modality_learning_for_localisation/tabs/cnn_details}
\label{subsubsec:cnn_aggregation}
In \ac{cnn} based methods, feature aggregation is also a subject of study. There are two different aspects of aggregation in \ac{cnn} domain: gathering of features extracted from networks and intra-pooling of deep features within the \ac{cnn}.

\begin{description}
	\item[Multiple features aggregation.] \ac{cnn} descriptor can be combined with local or patch detectors, in order to obtain sparse representation of the data (see table~\ref{tab:cnn_details} for examples). In this case, features extracted from the image can be gathered into a single descriptor, like in the BoF framework. VLAD embedding is employed in~\citep{Yan2016} and in~\citep{Panphattarasap2016} patches are sorted according to their relative position in the image and aggregated in a Landmark Distribution Descriptor (LDD) to improve the subsequent similarity search. \citet{Zhi2016} exploit the intensity response of each patches to discard the descriptors with the lowest intensity. In~\citep{Iscen2017}, authors create panorama features by aggregating multiple image representations (extracted from a \ac{cnn}) in a memory vector.
	
	\item[Pooling of deep feature maps.]	The meaningful representation of an image through neural network is achieved by extracting responses of convolutional layers~\citep{Babenko2014,Sunderhauf2015}. A convolutional layer can be seen as a 	feature bloc, composed of several activation maps of the same size. Considering the raw response of such a layer results in a high dimensionality feature vector. In order to capture a more discriminative image representation, several activation map pooling methods are applied. Table~\ref{tab:cnn_details} presents the different convolutional layer aggregation scheme employed in \ac{vbl}. Maximum Activation of Convolutions (MAC)~\citep{Razavian2014a} reduce the feature size by aggregating the maximum of each activation maps into unidimensional vector. Sum-Pooled Convolutional features (SPoC)~\citep{Babenko2015} shows superior results compared to MAC aggregation. Instead of computing the maximum over all the activation maps, authors simply sum the responses for each map. Regional Maximum Activation of Convolutions (R-MAC)~\citep{Tolias2016} is an improvement of the precedent MAC method, consisting of the computation of the maximum of activation over regions of various sizes on the activation map. \citet{Gordo2016} achieve state-of-the-art performances by combining R-MAC representation with a custom Region Proposal Network (RPN) that autonomously detects regions on the activation map to compute the max-pooling. An entirely trainable aggregation layer, called NetVLAD, have been proposed in~\citep{Arandjelovic2017}. Authors design a differentiable architecture that aim to mimic VLAD aggregation scheme. In combination with an adapted training framework, this architecture seems to be the best suited for \ac{vbl} tasks. \citet{Kim2017a} use the NetVLAD aggregation layer coupled with an Contextual Reweighing Network (CRN) to downgrade irrelevant features according to their local neighbourhood, without the use of any manually annotated data.
\end{description}						