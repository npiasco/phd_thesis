\section{Challenging localization scenarios}
\label{sec:chall_loc}

As mentioned previously, at first glance our method is not well designed to perform night to day matching. In this section, we conduct experiments in order to explain the results previously obtained and we propose an enhanced version of our descriptor performing much better on this challenging scenario.

\subsection{Night to day localization}
\label{subsec:night2day}

Night to day localization is an extremely challenging problem: our best RGB baseline achieves a performance less than 13\% recall@1. This can be explained by the huge difference in visual appearance between night and daytime images, as illustrated in figure~\ref{fig:dataset}. Our system should be able to improve the RGB baseline relying on the learned scene geometry, which remains the same during day and night. Unfortunately, we use training data exclusively composed of daytime images, thus making the decoder unable to reconstruct a depth map from an image taken at night. The last line of figure~\ref{fig:mod_ex} shows the poor quality of decoder output after initial training. In order to improve the decoder's performances, we propose to use weakly annotated data to fine tune the decoder part of our system. We collect 1000 pairs of image and depth map acquired at night and retrain only decoder weights $\theta_g$ using the loss of equation~(\ref{eq:l1_loss}). Figure~\ref{fig:mod_ex} presents the qualitative improvement on the inferred depth map after the fine tuning. Such post-processing trick cannot be used to improve standard RGB image descriptors, because we need to know the location of the night data. For instance, we use a night run from the Robotcar dataset with a low quality GPS signal, that makes impossible the automatic creation of triplets that are essential for training a deep image descriptor. 

We show in figure~\ref{fig:ft_night}-c that we are able to nearly double the localization performances by only fine tuning a small part of our system. Our best network achieves 23\% recall@1 against 13\% recall@1 for the best RGB baseline. We present some daylight images returned after the nearest neighbor search in figure~\ref{fig:night_im_exs}. Even with blurry images, our method is able to extract useful geometric information to improve the matching (see figure~\ref{fig:night_im_exs}, 3$^{rd}$ row).

\input{3_side_modality_learning_for_localisation/figures/chall_loc/night_ft}

\input{3_side_modality_learning_for_localisation/figures/chall_loc/night_ft_loc_res}

\subsection{Impact of fine tuning on other environments}
\label{subsec:night2day_inf}
In this section, we measure the impact of the fine tuning process on other localization scenarios. Performances could decrease if our system \textit{``forgets''} how to produce depth map from daylight images. To prevent that, we integrate half of daylight images with the night images in the training data used for fine tuning. 

We show results of the fine-tuned network on figure~\ref{fig:ft_night}. Localization accuracy remains stable after the fine tuning. We even observe slight increase in the localization performances for some scenarios (figure~\ref{fig:ft_night}-b): thank to the fine tuning with night images, the decoder has improved the depth map generation of dark images acquired during daytime. The fact that fine tuning our system, to deal with hard localization scenarios, do not negatively impact the performances on other environment makes our new method well suited for real applications when we cannot predict what will be the outdoor conditions.

\input{3_side_modality_learning_for_localisation/figures/chall_loc/night_im_exs}

