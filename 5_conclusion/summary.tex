In this final chapter, we summarize the main contributions of this thesis and we propose future research directions regarding the presented solutions.

\section{Summary of the thesis}

Throughout this thesis, we focus on \ac{vbl} in urban environment. We define the boundaries of our research in the first chapter. In chapter~\ref{chap:2}, we review exhaustively \ac{vbl} related fields and methods, with a particular attention paid to challenges induced by long-term localization and to the data heterogeneity presents in the localization approaches. We came out with the conclusion that they are a lake of methods taking advantages of asymmetric data, \ie different data modalities in the query side and in the database used as reference map. For instance, the query is often composed of a single modality, radiometric information, whereas the database is composed of multiple sensors information, like scene geometry, semantic and images.

In the chapter~\ref{chap:3}, we propose a new trainable global image descriptor for \ac{cbir} for localization. Our method is built on the powerful NetVLAD~\citep{Arandjelovic2017} image descriptor, combined with a modality transfer model capable of generating a depth map from a single image. The particularity of our method remains in the fact that our descriptor can be trained using side modality that is not available during the task of localization. We show that spreading out geometric clues within our pure radiometric descriptor improve the performances in challenging long-term localization scenarios. We are able to improve location accuracy for various realistic scenarios, involving cross-season data and nocturnal images. We show that our method can take advantages of not-only geometric information but also reflectance given by laser scan sensor.

Chapter~\ref{chap:4} is dedicated to our relocalization pipeline. Our method aims to improve the localization given by our initial localization step. Using geometric reasoning, we refine 6-\ac{dof} pose of the query to localize. In order to do so, we establish dense 2D to 2D correspondences between the query and retrieved examples returned by our initial localization step. The matching is computed thanks to deep features extracted from a \ac{cnn}. We define our method to be lightweight and easily plugged after an existing \ac{cbir} for localization approach. In a same manner as our global image descriptor, the relocalization is aided by the geometric information learned during an offline stage. Indeed, the 2D to 2D matches are not sufficient to recover the truth  6-\ac{dof} pose of the query and the extra geometric information is used to constrain the final pose estimation. Through comprehensive experiments, we demonstrate the effectiveness of our method in both indoor and outdoor scenes.
