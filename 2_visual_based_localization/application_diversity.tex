\section{Data heterogeneity}
\label{sec:application}	

\input{2_visual_based_localization/figures/data_hetero/data_hetero}

	Originally, images were the dedicated data to \ac{vbl} system~\citep{Robertson2004}. Still, conventional images for the task of localization have limitations, as mentioned in the previous section (see Section~\ref{sec:changing_environment}). The use of other type of data, such as geometric and semantic information, can circumvent these limitations.

	\subsection{Geometric information}
		\label{subsec:geometric_info}
		As presented in the outlines of this section, adding geometric information aims to overcome the limitations of only-based-optical \ac{vbl}.
        
		\paragraph{Weak Geometry}
			\label{subsubsec:weak_geometry}			
			In \citep{Torii2015,Chen2011}, authors introduce weak geometric clues that describe principal 3D planes present in the scene. This information is then used to modify existing images in the database: for rectification purpose~\citep{Chen2011} or to generate more images in order to cover a larger area~\citep{Torii2015}. \citet{Cham2010} use a 2D buildings outline map for \ac{vbl}. From a given image, authors extract buildings corner and match them according to the map. Along the same line, \ac{vbl} method from~\citep{Arth2015} relies on a 2.5D map of Gratz (schematic buildings outlines boxes from OpenStreetMap\footnote{https://www.openstreetmap.org}). 2D map is also used as geo-reference in the work from~\citep{Brubaker2013} (extended version in~\citep{Brubaker2016}) where authors produce, thanks to a stereo-camera, a path of a vehicle that is afterwards matched against the map. The matching process is embedded in a probabilistic framework to handle large environment. \citet{Baatz2012} introduce the use of a \ac{dem} to perform localization in mountainous terrain~\citep{Ramalingam2010,Tzeng2013,Chen2015}. \citet{Bansal2014} extend this idea in urban localization to perform purely geometric \ac{vbl} with images as query input and \ac{dem} of a city as database. These purely geometric descriptions, also used in~\citep{Matei2013,Christie2016,Ramalingam2010,Ramalingam2011} (see figure~\ref{fig:3d_info}), permit localization independently of the illumination conditions (compared to optically dependant methods, see \S\ref{para:illum}).

		\paragraph{3D geometry}
        \label{subsubsec:3d_geometry}
			Previous section \S\ref{subsec:sfm_methods} emphasizes the growing importance of colourized point clouds obtained by \ac{sfm} in \ac{vbl}. Because such geometric models are built upon images collections, reconstructed point clouds also lie on two categories: homogeneous~\citep{Kendall2015,Kendall2016} and heterogeneous~\citep{Irschara2009,Sattler2011} models (see \S\ref{para:data_consistency}). The addition of geometric relation by \ac{sfm} improves retrieval performances~\citep{Sattler2012a} and permits precise pose estimation of the query, on the contrary of methods based on vanilla images collections.

			However, \ac{sfm} reconstruction is a costly operation. Rather than preprocessing the visual data to recover the geometry of the scene, appropriate sensors permit a direct capture of a 3D scene (\textit{e.g.} stereo camera, depth camera, laser, lidar, etc.). Raw data from depth sensor are often used to add supplementary information channel to the \ac{vbl} system. Works from~\citep{Ni2009,McManus2014,Wan2014} use disparity map from stereo camera. Several authors~\citep{Shotton2013,Guzman-rivera2014,Glocker2015} used active depth camera that project infra-red pattern to estimate depth. Similar technology is used in~\citep{Li2016a} to perform \ac{vbl} in complete obscurity. Consistent 3D models are also used to perform \ac{vbl} task. For indoor localization, works from \citep{Shotton2013,Pascoe2015} use textured model reconstructed from RGB-D sensor~\citep{Shotton2013} or hand-crafted with dedicated software~\citep{Pascoe2015}. City-scale models are used by \citep{Aubry2014,Poglitsch2015,Pascoe2015a,Pascoe2015b,Caselitz2016} to perform outdoor \ac{vbl}. 

\input{2_visual_based_localization/tabs/data_types}

	\subsection{Semantic information}
		\label{subsec:semantic_info}
		Robustness and precision brought by geometric information has a significant cost in term on data acquisition, processing power and storage needs. Nevertheless, there is a good alternative and discriminant data representation: the semantic information. Semantic representation has received a growing interest in research community~\citep{Liu2016a}, in particular for robot navigation purpose~\citep{Kostavelis2015}. Semantic-based methods are notably efficient to perform robust \ac{vbl} to all kind of appearance changes. Indeed, by capturing a meaningful information about the scene composition, this approach is by definition invariant to local changes in appearance and in geometry. Semantic information used in \ac{vbl} are classified between two classes: segmentation and categorization. Segmentation involves local methods that recognize within a data sub-parts with a semantic meaning (\textit{e.g.} object detection in an image). On the other hand, categorization can be seen as global descriptors that associated semantic labels to a given data (\textit{e.g.} scenes interpretation~\citep{Deng2009}).
		
		\paragraph{Segmentation}
			The world ``semantic'' can be understood in different ways: \citet{Fernandez-Moral2013} semantic approach consists of extracting planar surfaces in a scene, while in~\citep{Salas-Moreno2013} authors segment a point cloud to extract objects with higher semantic meaning, like chair or table. Semantic approaches encode the data with a graph where nodes represent objects (plan in~\citep{Fernandez-Moral2013}, furnitures in~\citep{Salas-Moreno2013}) and edges spatial relations between objects. Graph representation offers a compressed data representation capable to handle local changes and minor measurement errors~\citep{Stumm2015}. Semantic segmentation is used in~\citep{Lu2015} to narrow the search scope and in~\citep{Ardeshir2014,Castaldo2015,Christie2016} to directly recover the pose of the query (illustration on figure~\ref{fig:seg_ifo}). Works described in~\citep{Arandjelovic2014a,Mousavian2015} consider the re-weighting of extracted local features in image according to the semantic class of the pixel obtained by image segmentation. Using this information, authors reduce the influence of local features that are not semantically robust for \ac{vbl}, like vegetation or cars. In a same manner, \citet{Arth2015} present concrete application of semantic segmentation of an image to reinforce hypothesis about building facades segmentation (the image is segmented with a SVM classifier). On the other hand, several methods rely on annotated map~\citep{Atanasov2016,Wang2015} or Geographic Information System (GIS)~\citep{Ardeshir2014,Castaldo2015,Qu2015} to guide the localization.
	    	
		\paragraph{Categorization}
			Scene categorization~\citep{Wu2009} is a different manner to exploit semantic clues for \ac{vbl}. High level semantic features have been popularized with the augmentation of labelled data and the accessibility of high computation power devices (GPU, Cloud Computing). ImageNet challenge introduced in 2009 by~\citep{Deng2009} permits the emergence of fast and robust classification methods, like the one described in~\citep{Krizhevsky2012}. Image classification produces a sub-sample of semantically identical images associated to a class. In \ac{vbl}, classification can be used to decimate the database in order to proceed in a subsequent step to a more precise pose search. This method is successfully applied in~\citep{Sunderhauf2015}, where the used \ac{cnn} has a dual-purpose: narrowing the search scope by semantic labelling and producing a global descriptor by weight aggregation (see \S~\ref{para:global_cnn}). In~\citep{torralba2003context,Ni2009}, classical learning methods like Gaussian Mixture Models (GMM) or epitome are employed for associating images to a finite number of possible locations. Recent work from~\citep{Garg2017} use semantic categorization in order to establish transition probabilities from a given type of environment to another one. Authors embed this framework in the SeqSLAM algorithm, improving the global system accuracy. Finally, works presented in~\citep{Hays2008,Weyand2016} consider the problem of classification of images at a world-wide level.
			
	\subsection{Cross-data localization}
	\label{subsec:cross_data}        
		We have presented so far three different kinds of information that can be used for \ac{vbl}: optical, geometric and semantic. These types of data are commonly used together to improve localization. In this part, we consider the scenario where all types of data are not available at query time, for instance if the database uses more complete representation of the environment than the query input. It is a common scenario because some data are more difficult to acquire or required specific sensors (\eg geometric information). In this case, methods have to deal with asymmetric representation of the environment in term of data type. We denote this problem cross-data \ac{vbl} and classify the methods founded in the literature in two categories: methods using a common description regardless of the type of data and methods projecting one type of data within another data representation space.
		
    	\paragraph{Common description}
    		Features to Points (F2P) \ac{vbl} (see \S\ref{subsec:sfm_methods}) oppose 2D images to 3D point cloud. In fact, all the features are exclusively extracted from images. On the other hand, semantic abstraction permit cross-data comparison by considering semantic object extracted from various types of data: images to 2D building outline map~\citep{Cham2010}, images to map~\citep{Ardeshir2014,Qu2015,Castaldo2015,Brubaker2016}, RGB-D data to \ac{dem}~\citep{Christie2016}, etc. Referring to a similar physical entity, not necessary semantic, is also a manner to link information from various types of data. Images to DEM correspondences is performed in \citep{Bansal2014} based on a method relying on purely geometric clues extracted both in the image and the model. Recent work from \citep{Sizikova2016,Li2017} use joint descriptors to merge RGB and depth data into a single feature.
					
		\paragraph{Data projection}
			Another widely used method for combining data of different types consists of projecting one of the engaged data into the representation space of the other. For instance, lot of methods consider the challenging problem of registering photographies upon 3D models~\citep{Baatz2012,Kendall2015,Arth2015,Pascoe2015,Pascoe2015a,Pascoe2015b}. Similarity comparison is performed thanks to synthetic images generated from the 3D models \citep{Russell2011,Mason2011,Aubry2014,Poglitsch2015}. Notice the synthesis of skyline profiles from DEM in the work of \citet{Baatz2012}. Special attention is paid to placement of the artificial cameras that generate fake 2D views \citep{Irschara2009,Gee2012,Torii2015}: \citet{Aubry2014} generate cameras over a regular grid to cover a maximal area. A pruning is then applied to only keep the most discriminant views.

To conclude this section, the different types of data used in \ac{vbl} methods are summarized in table~\ref{tab:data_types}.

