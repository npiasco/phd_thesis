\section{Data Representation}
\label{sec:image_representation}
	What is the best manner for representing visual data? This central question, present in various Computer Vision, Robotic and Photogrammetric applications, leads up to numerous answers. The data representation, termed features, should incorporate as much as possible discriminant information from the initial visual document and be fast to compute and compare. We present in this section representations used in \ac{vbl}. Table~\ref{tab:features_list} summarizes the following presented features.
		
	\subsection{Local Features}
	\label{subsec:local_feature}
		Local features are widely used in \ac{vbl} and more generally in Computer Vision. Their description occurs at pixel level among a local neighborhood of several points in the image. The description through local features is two-step: firstly detect salient region (the extraction phase) and then characterize them according to their neighborhood (the description phase).
				
		\paragraph{Point features.} 
			Several criteria are taken into account for the selection of point features:~scale, orientation and illumination invariance, as well as computational cost and descriptor vector dimension. A comprehensive list of local feature descriptors used in topological mapping in robotics can be found in~\citet{Garcia-Fidalgo2015} survey. \citet{Krajnik2017a} explore in-deep many combination of detector/descriptor for the specific task of images matching across seasons. The most used point feature in \ac{vbl} remains the Hessian-affine detector~\citep{Mikolajczyk2004} combined with SIFT~\citep{Lowe2004} descriptor. Important contribution from~\citet{Arandjelovic2012} introduces RootSIFT which presents better results in matching step with minor overhead in computational load. SURF descriptors~\citep{Bay2006}, light version of SIFT, are employed when real-time performance are required~\citep{Cummins2008,Qu2016,Stumm2016}. Interesting work from~\citet{Feng2016a} combines rapidity and precision by using binary BRISK descriptor~\citep{Leutenegger2011brisk}.
        
	        Learned local features is a well studied topic~\citep{Carlevaris-Bianco2014,Paulin2015,Yi2016a,Ono2018a,Dusmanu2019,DeTone2017,Detone2018}. Features are detected and described through \ac{cnn} trained for the task of similar features association. \citet{Schonberger2017} propose a recent comparison of hand-crafted and learned feature proposed and show, amongst others, that traditional local features perform the best in some scenario related to \ac{vbl}. In~\cite{Sarlin2018a}, authors use SuperPoint~\citep{Detone2018} as local features for images localization. D2-Net~\citep{Dusmanu2019} have also been successfully applied to \ac{vbl}. Features block extracted from a \ac{cnn} can also serve as densely sampled local keypoints~\citep{Widya2018} (each keypoint is extracted along the depth of the features block). This dense extraction of local features have been successfully used for \ac{vbl} in~\citep{Piasco2019a,Taira2018}. Attention mechanism can be added to select discriminative areas from the dense features block, as illustrated with the weakly supervised DELF~\citep{Noh2017} system trained for large scale image localization.

		\paragraph{Geometric features.}
		 	Visual data can be described by primitive geometric shapes. Despite the fact that geometric features are less compliant than point features, they include semantically meaningful information. For example, vertical lines are convenient descriptor in urban environment to represent buildings~\citep{Arth2015,Morago2016,Ramalingam2011}. On the basis of this observation, \citet{Hays2008} introduce line extraction in combination with others descriptors to describe images. Works in~\citep{Cham2010} introduce a semantic line-based descriptor. The vertical lines are extracted using Canny filtering and coded into VCLH (Vertical Corner Line Hypothesis) for meaningful building corners representation. Contour extraction have also been employed by~\citet{Russell2011} to recover the pose of an image in a site of archaeological excavations. In the work of \citet{Baatz2012}, authors assume that skyline will be present in the data and use it as a geometric features to describe mountain panoramas. Dehaze segmentation is used to extract the skyline that is thereafter encoded in a curve bin descriptor.
		 	
		 	Considering 3D data, several works use three-dimensional geometric features like normal vectors~\citep{Li2016} or planar surfaces~\citep{Fernandez-Moral2013}. \citet{Bansal2014} use PointRay (\ie a 3D vectors aligning with an edge) extracted from a \ac{dem} to represent building corners. With recent progress of \ac{dl} on 3D point cloud processing~\citep{Qi2016a}, local learned point feature descriptors for localization have emerged. 3DMatch~\citep{Zeng2016}, 3DFeat-Net~\citep{Yew2018} and PPFNet~\citep{Deng2018} are a 3D point descriptor trained for the task of 3D points to 3D points registration and used to localize a local laser scan within a reference point cloud.
			
		\paragraph{Point features with geometric relations.}
        	The lack of geometric consistency across the whole image is a shortcoming associated with point features. Various contributions propose to overcome this limitation by adding local geometric information directly on the point descriptor~\citep{Baatz2012,Jegou2008} or with the geometric association of numerous points~\citep{Liu2012,Li2015}. SIFT features contain scale and orientation information, that have been originally used in~\citep{Jegou2008} through the Weak Geometry Consistency framework. Following the same idea, \citet{Baatz2012} encode features relative pose in the image to perform geometric verification at matching time. \citet{Liu2012} introduce a geometric descriptor called Virtual Line Descriptor (VLD) by connecting two local features with each other. The subsequent lines are used to reinforce the robustness of the matching process in \ac{vbl} scenario~\citep{Majdik2013}. \citet{Li2015} propose a different pairwise geometric descriptor (PGM), showing great results on both urban and landscape scenes.
			
	\subsection{Global Features}
	\label{subsec:global_feature}
		Another description approach considers the image as a whole and produces one signature with high dimensionality (usually up to 4096 elements). Compared to local descriptors, global features are considered less robust in viewpoint changes, occlusion and local variations in the image. However, they are computationally less intensive to extract and capture a comprehensive description of the visual data. With the recent progress on \ac{ml}, a new class of very efficient global descriptor computed by \ac{cnn} have emerged.
		
		\paragraph{Hand-crafted features}
		 	GIST descriptor introduced by~\citet{Oliva2001} is the most used hand-crafted global descriptor in \ac{vbl}~\citep{Russell2011,Azzi2016,Hays2008}. The raw image can serve as a descriptor, with systematic resizing in order to obtain thumbnail~\citep{Hays2008,Corke2013} (potentially augmented with depth information~\citep{Gee2012}). Simple descriptor computed through an histogram upon various criteria (color, texture~\citep{Hays2008} or depth~\citep{Ni2009}) also provides a fast global information. Taking the image as a whole in a different representation space that is more discriminant for similarity research can also be considered as global description. For instance, \ac{ft} is used by~\citet{Wan2016}.
			
		\paragraph{Learned features}
			\label{para:global_cnn}
			Democratization of \ac{cnn} in computer vision domain leads to state-of-the-art techniques in image retrieval for urban scenes~\citep{Arandjelovic2017,Gordo2016,Kim2017a,Radenovic2016}. Descriptors created through \ac{cnn} are obtained using pooling mechanism on the computed features block~\citep{Babenko2014}. We refers readers to \acl{sec}~\ref{subsec:cnn_as_global_desc} for a detailed review on learned global image descriptor for the task of \ac{vbl}. 
			
			Similar learned approaches have been recently used for 3D point cloud global description~\citep{Uy2018,Schonberger2017a}. \citet{Schonberger2017a} combine 3D convolution on point cloud (the 3D information is stocked in volumetric grid of voxels) and an self-supervised deep auto-encoder and use the low dimensional latent representation computed by the network as global point cloud descriptor. In~\citep{Uy2018} the PointNet~\citep{Qi2016a} network is associated to a differentiable \ac{vlad} module, called NetVLAD~\citep{Arandjelovic2017}, to train in a supervised manner a discriminative global feature for fast localization.

	\subsection{Patch features}
		\label{subsec:hybrid_feature}
		Patch features consider region of interest in the image, it can be interpreted as a compromise between local and global features. The patch could be manually extracted (with a fixed grid on an image, or a sliding window~\citep{Dalal2005}) or automatically chosen in according to image saliency~\citep{Matas2004}. The discriminative HOG~\citep{Dalal2005} descriptor has been used in \ac{vbl} for capturing architectural cues of building and landmarks~\citep{Shrivastava2011, Aubry2014, McManus2014,Morago2016}. In the work of~\citep{Nister2006,Kim2015}, MSER blob detector by \citet{Matas2004} is used to extract visual information. \citet{Morago2016} use a combination of local and patch features to describe repetitive shapes. Patch detector coupled with global descriptors are a common use in \ac{vbl}, as illustrated in \citep{Kim2015,Gordo2016,Sunderhauf2015a,Yan2016}. \citet{Sunderhauf2015a} present promising works where the feature patches are automatically extracted with an edge boxes detector~\citep{Zitnick2014}. Another \ac{cnn} approach is introduced to perform \ac{vbl} in \citep{Gordo2016}, authors use a custom region proposal network~\citep{Ren2015} to extract \acp{roi} and compute a deep representation of the \ac{roi}.
			
\input{2_visual_based_localization/tabs/features_list}		