\section{Data Representation}
\label{sec:image_representation}
	What is the best manner for representing visual data? This central question, present in various Computer Vision, Robotic and Photogrammetric images-indexing applications, leads up to numerous answers. The data representation, termed features, should incorporate as much as possible discriminant information from the initial visual document and be fast to compute and compare. We present in this section representations used in \ac{vbl}. Table~\ref{tab:features_list} summarizes the following presented features.
		
	\subsection{Local Features}
	\label{subsec:local_feature}
		Local features are widely used in \ac{vbl} and more generally in Computer Vision. Their description occurs at pixel level among a local neighborhood of several points in the image. The description through local features is two-step: firstly detect salient region (the extraction phase) and then characterize them according to their neighborhood (the description phase).
				
		\paragraph{Point features.} 
			Several criteria are taken into account for the selection of point features:~scale, orientation and illumination invariance, as well as computational cost and descriptor vector dimension. A comprehensive list of local feature descriptors used in topological mapping in robotics can be found in~\citet{Garcia-Fidalgo2015} survey. \citet{Krajnik2017a} explore in-deep many combination of detector/descriptor for the specific task of images matching across seasons. The most used point feature in \ac{vbl} remains the Hessian-affine detector~\citep{Mikolajczyk2004} combined with SIFT~\citep{Lowe2004} descriptor. Important contribution from~\citet{Arandjelovic2012} introduces RootSIFT which presents better results in matching step with minor overhead in computational load. SURF descriptors~\citep{Bay2006}, light version of SIFT, are employed when real-time performance are required~\citep{Cummins2008,Qu2016,Stumm2016}. Interesting work from~\citet{Feng2016a} combines rapidity and precision by using binary BRISK descriptor~\citep{Leutenegger2011brisk}.
        
	        Learned local features is a well studied topic~\citep{Carlevaris-Bianco2014,Paulin2015,Yi2016a,Ono2018a,Dusmanu2019,DeTone2017,Detone2018}. Features are detected and described through \ac{cnn} trained for the task of similar features association. \citet{Schonberger2017} propose a recent comparison of hand-crafted and learned feature proposed and show, amongst others, that traditional local features perform the best in some scenario related to \ac{vbl}. In~\cite{Sarlin2018a}, authors use SuperPoint~\citep{Detone2018} as local features to localize images. D2-Net~\citep{Dusmanu2019} have also been successfully applied to \ac{vbl}. Dense features block extracted from a \ac{cnn} can also serve as local keypoints~\citep{Widya2018} (each keypoint is extracted along the depth of the features block). This dense extraction of local features have been successfully used for \ac{vbl} in~\citep{Piasco2019a,Taira2018}. Attention mechanism can be added to select discriminative areas from the dense features block, as illustrated with the weakly supervised DELF~\citep{Noh2017} system trained for large scale image localization.

		\paragraph{Geometric features.}
		 	Visual data can be described by primitive geometric shapes. Despite the fact that geometric features are less compliant than point features, they include semantically meaningful information. For example, vertical lines are convenient descriptor in urban environment to represent buildings~\citep{Arth2015,Morago2016,Ramalingam2011}. On the basis of this observation, \citet{Hays2008} introduce line extraction in combination with others descriptors to describe images.  Contour extraction have also been employed by~\citet{Russell2011} to recover the pose of an image in a site of archaeological excavations. 
		 	
		 	Considering 3D data, several works use three-dimensional geometric features like normal vectors~\citep{Li2016} or planar surfaces~\citep{Fernandez-Moral2013}. With recent progress of \ac{dl} on 3D point cloud processing~\citep{Qi2016a}, local learned point feature descriptors for localization have emerged. 3DMatch~\citep{Zeng2016}, 3DFeat-Net~\citep{Yew2018} and PPFNet~\citep{Deng2018} are a 3D point descriptor trained for the task of 3D points to 3D points registration and used to localize a laser scan within a reference point cloud.
			
		\paragraph{Point features with geometric relations.}
        	The lack of geometric consistency across the whole image is a shortcoming associated with point features. Various contributions propose to overcome this limitation by adding local geometric information directly on the point descriptor~\citep{Baatz2012,Jegou2008} or with the geometric association of numerous points~\citep{Liu2012,Li2015}. SIFT features contain scale and orientation information, that have been originally used in~\citep{Jegou2008} through the Weak Geometry Consistency framework. Following the same idea, \citet{Baatz2012} encode features relative pose in the image to perform geometric verification at matching time. \citet{Liu2012} introduce a geometric descriptor called Virtual Line Descriptor (VLD) by connecting two local features with each other. The subsequent lines are used to reinforce the robustness of the matching process in \ac{vbl} scenario~\citep{Majdik2013}. \citet{Li2015} propose a different pairwise geometric descriptor (PGM), showing great results on both urban and landscape scenes.
			
	\subsection{Global Features}
	\label{subsec:global_feature}
		Another description approach considers the image as a whole and produces one signature with high dimensionality (a vector with up to 4096 elements). Compared to local descriptors, global features are considered less robust in viewpoint changes, occlusion and local variations in the image. However, they are computationally less intensive to extract and capture a comprehensive description of the visual data. With the recent emergence of \ac{cnn}, a new class of very efficient global descriptor have been created.
		
		\paragraph{Hand-crafted features}
		 	GIST descriptor introduced by~\citet{Oliva2001} is the most used hand-crafted global descriptor in \ac{vbl}~\citep{Russell2011,Azzi2016,Hays2008}. The raw image can serve as a descriptor, with systematic resizing in order to obtain thumbnail~\citep{Hays2008,Corke2013} (potentially augmented with depth information~\citep{Gee2012}). Simple descriptor computed through an histogram upon various criteria (color, texture~\citep{Hays2008} or depth~\citep{Ni2009}) also provides a fast global information. Taking the image as a whole in a different representation space that is more discriminant for similarity research can also be considered as global description. For instance, \ac{ft} is used by~\citet{Wan2016}.
			
		\paragraph{Learned features}
			\label{para:global_cnn}
			Democratization of \ac{cnn} in computer vision domain leads to state-of-the-art techniques in image retrieval for urban scenes~\citep{Arandjelovic2017,Gordo2016,Kim2017a,Radenovic2016}. Descriptors created through \ac{cnn} are global features collected by grouping weights of a given layer into a single vector~\citep{Babenko2014}. Table~\ref{tab:cnn_details} presents main \ac{cnn} architectures involved in \ac{vbl}. Firstly, \ac{cnn} have been used for the task of localization without special training, exploiting inherent domain transfer capability of neural network. It is also interesting to notice that the most discriminative descriptors for the task of image-retrieval are extracted from mid-level convolutional layers instead of fully-connected layers~\citep{Babenko2014,Sunderhauf2015}.
			
			In recent works~\citep{Arandjelovic2017,Radenovic2016, Gordo2016}, authors tackle the problem of fine tuning a pre-trained network for the specific task of similar images association. \citet{Arandjelovic2017} introduce a weakly supervised triplet ranking loss, feeding the network with positive and negative examples before applying the back-propagation. Positive examples are candidates related to a query image and negative examples are non-relevant candidates. Works in~\citep{Radenovic2016, Gordo2016} use a different approach: two~\citep{Radenovic2016} or three~\citep{Gordo2016} identical networks receive negative and/or positive examples at each iteration, and the back-propagation is operated on the different networks. By sharing the weights between the different networks and by applying a relevant common loss, the system can learn a data representation suitable for similarity research.	Authors insist on the need of having a clear and large database. Therefore, works from~\citep{Radenovic2016, Gordo2016} introduce novel methods to automatically reject wrong images, cluster the data into similarity groups and associated positive images with hard negative samples (\textit{e.g.} very dissimilar images) for training. The Time Machine functionality of Google Street-View is used in~\citep{Arandjelovic2017} to gather a large database composed of the same places at different periods of time. Data synthesis by view rendering is also performed for gathering large amount of data~\citep{Jia2016,Sizikova2016}.  Pre-treatment on training data are more generally used with learning-based methods~\citep{Kim2015,Cao2013}. 
	
			Further explanations regarding \ac{cnn} and specially aggregation methods performed inside the network can be found in the next section~\S\ref{subsubsec:cnn_aggregation}.

	\subsection{Hybrid Features}
	\label{subsec:hybrid_feature}
		We have decided to call hybrid features two different kinds of approaches: the first one consider features that cannot be considered neither as local nor global (i.e. patch or blob) and the second one are features that combine several types of descriptors.
		\paragraph{Patch features}
			Patch features consider region of interest in the image, it can be interpreted as a compromise between local and global features. The patch could be manually extracted (with a fixed grid on an image, or a sliding window~\citep{Dalal2005}) or automatically chosen in according to image saliency~\citep{Matas2004}. The discriminative HOG~\citep{Dalal2005} descriptor has been used in \ac{vbl} for capturing architectural cues of building and landmarks~\citep{Shrivastava2011, Aubry2014, McManus2014,Morago2016}. In the work of~\citep{Nister2006,Kim2015}, MSER blob detector by \citet{Matas2004} is used to extract visual information. \citet{Sunderhauf2015a} present promising works where the feature patches are automatically extracted with an edge boxes detector~\citep{Zitnick2014}. Another \ac{cnn} approach is introduced to perform \ac{vbl} in \citep{Gordo2016}, authors use a custom region proposal network~\citep{Ren2015} to extract regions of interest.
			
		\paragraph{Combined features}
			Image features are often combined to provide a complementary description of the scene. \citet{Hays2008} combine up to 5 global and local descriptors to qualify images. \citet{Azzi2016} use features in a cascade scheme to first narrow the search scope with global feature GIST and then select the good candidates with local features SIFT. Similar approaches are used with learned image representation in~\citep{Sarlin2018a,Sarlin2018,Rocco2018,Sattler2017,Piasco2019a,Taira2018,Dusmanu2019}. \citet{Morago2016} use a combination of local and patch features to describe repetitive shapes. Patch detector coupled with global descriptors are a common use of multiple features, as illustrated in \citep{Kim2015,Gordo2016,Sunderhauf2015a,Yan2016}. Recent work from~\citet{Bhowmik2017} study a new approach for pairing various descriptors in order to increase the result of the retrieval step depending on the targeted dataset.
						
	\subsection{Semantic Features}		
	\label{subsec:semantic_representation}
		Previously presented data descriptors belong to an abstract class of features that focus on the raw data extracted from the acquisition sensor. On the contrary, semantic representation aims to categorize the data meaningfully. Works in~\citep{Cham2010} introduce a semantic line-based descriptor. The vertical lines are extracted using Canny filtering and coded into VCLH (Vertical Corner Line Hypothesis) to represent building corners. Skyline features introduced by~\citet{Baatz2012} have been used to describe mountain panoramas. Dehaze segmentation is used to extract the skyline that is thereafter encoded in a curve bin descriptor. More recently, \citet{Bansal2014} use \textit{PointRay} to represent building corners. We refer reader to \S\ref{subsec:semantic_info} for more investigation about semantic representation in \ac{vbl}.
		
\input{2_visual_based_localization/tabs/features_list}		