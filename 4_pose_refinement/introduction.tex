Many applications in Computer Vision and Robotics require a precise initial pose estimation of the visual data acquisition system: augmented reality~\citep{Arth2015}, visual odometry~\citep{Pascoe2015a}, SLAM~\citep{Milford2012} or visual servoing~\citep{Marchand2016}, to name a few. Coarse estimation provided from standard geo-localization system (\textit{e.g.} GPS) or \ac{cbir} for localization are not accurate enough for such applications, and other processing are required to initialize the system with a suitable pose. For instance, considering a system using pose initialization by \ac{cbir}, the reference database is never dense enough to ensure that it exist an example within this database at exactly the same pose as the query. Thus, the exact 6-\ac{dof} of the query cannot be recovered.

We introduce in the previous chapter a global image descriptor for localization under challenging condition. We are now considering the problem of pose refinement, in other words, the second step of our hierarchical \ac{vbl} system. In section~\ref{subsec:pose_refinement}, we mentioned two main approaches for pose refinement: image-based and model based. As our first localization step rely on image indexing, an image-based refinement method is more logical to implement. We also want to take advantage of an auxiliary modality in our refinement step. In an different way that in our global image descriptor introduced previously (see section~\ref{sec:preliminary_work}), we decide to use the learned depth maps to incorporate geometric constraints in our pose refinement process. 

For computing the real 6-\ac{dof} pose of a query, we first make dense correspondences between the query and the top retrieved images from our initial \ac{cbir} step. From these correspondences, we can estimate relative pose information with geometric algorithms. In order to obtain a position at true scale (which is not the case with traditional multi-view methods~\citep{Hartley2003}), we exploit the reconstructed depth map. We use the same neural model to compute the global image descriptor used in \ac{cbir}, the dense matching between the query and the retrieved image and to estimate the depth map associated to a single image. Thanks to this multi-task design, our system is compact and lightweight and can be used on various environment without specific retraining. Unlike model-based hierarchical \ac{vbl} methods, our proposal does not requires heavy representation of the scene geometry as we exploit the capability of recent neural networks to learn the underlying structure of a scene from the radiometric appearance.

For a comprehensive review of hierarchical methods for \ac{vbl}, please refer to section~\ref{subsec:pose_refinement}. The rest of this chapter is presented as follows: section~\ref{sec:method} is dedicated to the workflow explanation of our method, then we introduce the two geometric algorithms used to compute the relative pose of the query~\ref{sec:relative_pose}. We present explanatory results for indoor localization on section~\ref{sec:implementation} and we pursue more experiments on indoor localization on~\ref{sec:indoor}. Before the conclusion, we investigate unsupervised depth from monocular training as well as outdoor localization in section~\ref{sec:outdoor}. We finally conclude the chapter, after a short discussion, in section~\ref{sec:conclusion_pnlp}.
