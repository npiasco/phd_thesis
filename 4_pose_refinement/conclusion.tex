\section{Conclusion}
\label{seq:conclusion}

We have introduced a new method for online \ac{vbl} consisting of an initial pose estimation by \ac{cbir} followed by our new PnlP pose refinement. In order to achieve relative pose estimation at absolute scale, we learn to reconstruct the depth map associated to a monocular image to project into 3D densely matched 2D points between the query and the reference. The presented method is compact and fast as all the components needed by the localization pipeline are computed thanks to the same neural network in a single forward pass. Because our network learns the depth relative to the camera frame, not the absolute geometric structure of the scene, it can be used in unknown environment without fine tuning or specific training. 

In a future work, we will investigate multi-task learning in order to address all the computer vision problems involved in \ac{vbl} jointly, namely global image description, dense correspondences between images and depth from monocular.