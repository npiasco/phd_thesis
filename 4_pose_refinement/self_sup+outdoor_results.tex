\section{Unsupervised training and outdoor localization}
\label{subseq:outdoor}
\subsection{Unsupervised depth from monocular training}

\paragraph{Unsupervised depth from monocular at scale.} It is not self-explanatory to claim that the depth maps produced from our unsupervised trained network~\citep{Zhou2017a} are at a real scale. Nevertheless, in our experiment they are because we use the absolute 6-DoF camera pose (obtained by SfM) to compute the relative position and orientation of the training images. In~\citep{Zhou2017a}, authors use an auxiliary relative pose estimation network to make their method trainable with video sequences without any pre-processing. The counterpart is that the final CNN produces depth maps up to an unknown scale factor.

For the case of the Cambridge Landmarks dataset~\citep{Kendall2015}, authors rescale the 3D model obtained by SfM at true scale using control points to obtain meaningful pose error at test time. Some learned depth maps can be found in figure~\ref{fig:depth_map_indoor}, showing that unsupervised method leads to true scale depth values as long as it has been trained with true camera pose information.

\subsection{Comparison with fully-supervised training}
\input{4_pose_refinement/figures/results/indoor_depth_maps}


\subsection{Outdoor localization}
\input{4_pose_refinement/tabs/outdoor}
As mentioned previously, we only test our unsupervised set-up for outdoor image pose estimation as the Cambridge Landmarks dataset~\citep{Kendall2015} does not contain ground truth depth maps. Results are presented in table~\ref{tab:outdoor}. PnlP performs well on outdoor scene, with a mean improvement of $\times$1.3/$\times$1.4 for FC architecture, and $\times$1.5/$\times$1.6 for C+LSTM, in position/rotation precision over initial pose given by CBIR. Superior performances of C+LSTM model can be explained by a better capability of the recurrent cells in the C+LSTM decoder for modelling the 3D structure of the scene, as shown in figure~\ref{fig:depth_map_outdoor}. Our method is not able to recover a proper pose for the scene Street. As same as for the indoor failure case, this is the result of a poor initial pose estimation at the CBIR preliminary step. Compared to Posenet~\citep{Kendall2017}, our method is marginally less precise but requires only one trained model compared to the 6 models needed by Posenet and can potentially be used on unknown scenes according to the previous indoor experiments. We do not compare our method to Relocnet~\citep{Purkait2018} baseline because authors do not evaluate Relocnet on outdoor scenes.


\input{4_pose_refinement/figures/results/outdoor_depth_maps}