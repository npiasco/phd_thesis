\section{Review of 6-DoF camera pose estimation methods}
\label{sec:fine_pose_estimation}

	At this point, we introduce the notion of \textbf{direct} \ac{vbl} methods that instantly recover the exact 6 \ac{dof} pose of the query according to a known reference. Compared to indirect approaches, direct methods provide a more accurate query pose to the detriment of the area coverage. Indeed, direct \ac{vbl} requires a smaller database and in some case a coarse prior information about the query pose. From this class of methods, we consider the three following approaches:
	\begin{description}
		\item[Direct \ac{vbl} with prior:] these methods are built upon the assumption that we get a prior information about the query pose. The pose prior can be obtained through localization sensor (GPS~\citep{Chen2011,Arth2015,Poglitsch2015}, magnetic compass~\citep{Svarm2014,Zeisl2015,Svarm2016}) or by using an indirect \ac{vbl} system~\citep{Torii2011,Song2016,Sattler2017}.
		\item[Features to points matching:] this class of methods performs the global localization of the query by establishing correspondences between two-dimensional features extracted from an image and three-dimensional point cloud model of the environment (see figure~\ref{fig:direct}).
		\item[Pose regression approaches:] the last considered family of algorithms are methods that learn to directly regress from an input visual data to its corresponding pose. Standard regression techniques~\citep{Shotton2013} and \ac{cnn} architecture~\citep{Kendall2015} are employed to perform this task.
	\end{description}

	\subsection{Direct VBL with prior}
   		\label{vbl_prior}
		Many applications in Computer Vision and Robotics require an initial  pose estimation of the visual data acquisition system: augmented reality~\citep{Arth2015}, visual odometry~\citep{Pascoe2015a}, SLAM~\citep{Milford2012} or visual servoing~\citep{Marchand2016}, to name a few. Coarse estimation provided from standard geo-localization system (\textit{e.g.} GPS) are not accurate enough for such applications, and other processing are required to initialize the system with a suitable pose.
		
		\paragraph{Methods overview}
			\citet{Arth2015} introduce a method to estimate a fine pose of a mobile camera to initialize AR applications or SLAM systems. Given a coarse prior pose of the camera (obtained by GPS and compass embedded in a smart-phone), authors refine the global pose by matching extracted geometric features to buildings outlines. Similarly, \citet{Russell2011} investigate techniques to retrieve the pose of realistic painted or drawn piece of art according to recent photographies. Given a coarse pose prior, the query location is refined by establishing edges correspondences with the real model. \citet{Poglitsch2015} introduce a particle filter to perform localization. The particles are randomly generated over a 3D model from a coarse position information from a GPS sensor. Widely spread in robotic community, particle filters have also been used to refine a coarse pose of a mobile robot in known ground 3D space~\citep{Mason2011} or an aerial map~\citep{Christie2016,Brubaker2016}.
			
            Similar to work described in~\citep{Rubio2015,Sattler2017}, \citet{Song2016} present a typical cascade scheme to estimate the 6 \ac{dof} pose of a given image. The authors perform a first step indirect method to retrieve a set of potential similar candidates, and then refine the pose with relative pose computation algorithms. 
		
			An aerial localization of an unmanned aerial vehicle (UAV) from down-looking camera images is presented in~\citep{Wan2016}. Authors estimate a fine pose by registering the embedded camera image on a satellite images. A coarse pose information is needed for reducing the search scope. This solution is also validated for \ac{vbl} on foreign planet of the solar system. Over works present \ac{vbl} for lunar rover in extremely challenging condition~\citep{Wan2014}. In order to perform a fine pose estimation under hard conditions (lunar panorama with few discriminative visual elements), the authors have to use a reliable prior pose of the robot given by IMU and wheel odometers.
					
		\paragraph{Pose Computation}
        	\label{para:pose_compute}
			Numerous techniques can be applied to recover the exact 6 \ac{dof} of a given query. If the reference data are geo-localized images displaying primarily planar surfaces, homography retrieval can be employed~\citep{Forstner2016}. The relative pose from the query and the reference images can also be regressed with multi-view algorithms \citep{Hartley2003}. Nist\'er's 5-points algorithm \citep{Nister2004} or the 8-points algorithm by \citet{Hartley1997} are used in many \ac{vbl} scenario \citep{Qu2016}. Recently \ac{cnn} have been used to warp an affine or thin-plate-spline transformation between two images~\citep{Rocco2017}, or to estimate the relative transformation between two images~\citep{Melekhova}. Although not precise as classical methods, the presented network is able to deal with drastically different images in appearance. If numerous reference images are available, more complete methods are used involving trifocals geometry \citep{Hartley2003} like in \citep{Song2016}. \citet{Kneip2014opengv} introduce \texttt{OpenGV} library, a modern \texttt{C++} tool to compute relative and absolute pose with various algorithms.

		\paragraph{Pose refinement}
			Depending on the available data, heavier processing can be applied to refine the query pose. Bundle adjustment is the widely used technique when dealing with 3D structures or point cloud obtained from images. Works from~\citep{Middelberg2014,Wan2014,Forstner2016} apply bundle adjustment to refine the first guess pose from their method. Local bundle adjustment are used when real-time performances are targeted \citep{Li2010,Qu2016}. Another famous refinement method is the Iterative Closest Points algorithm (ICP), used in \ac{vbl} context in~\citep{Russell2011,Baatz2012,Morago2016}. \citet{Pani2015Lmi} provide algorithms to obtain an optimal alignment between images and point cloud data, or between point cloud and 3D model~\citep{Pani2015Robust}.
			
	\subsection{Features to Points matching}
		\label{subsec:sfm_methods}						
		A widely represented family of direct method aims to regress the pose of a camera based on the analysis of a 3D point cloud reconstructed by \ac{sfm} algorithms. The principle of these methods is to establish 2D features to 3D points correspondences (F2P). In a first step, three-dimensional representation of the environment is built thanks to many images. Triangulated points within this structure are associated to the local features (most of the time SIFT vectors~\citep{Lowe2004}) extracted from all the images where the considered point is visible. At query time, local features from the image to localize are matched against the set of pre-computed 3D points. Finally, the features to points correspondences permit a 6 \ac{dof} pose estimation of the acquisition system.
 
		These methods share a lot of similarity with indirect methods described in Section~\ref{sec:matching} and they present the same two-step pipeline:~data description and data similarity association. Yet the use of a geometrically structured database introduces interesting elements not exploitable in a classical image-retrieval scheme~\citep{Sattler2012a}.
		
		\paragraph{Methods overview}
			Between methods based on prior information and F2P methods, works from \citet{Arth2009} present a system that recover the pose of a smart-phone camera by confronting an image to a subset of 3D points that should be visible in the query according to a prior pose information. \citet{Irschara2009} introduce the first F2P method based on \ac{sfm} environment representation. Authors perform scalable \ac{vbl} by registering the point cloud into synthetic visual documents covering the entire model. Latter improvement by \citet{Li2010} reverse the conventional process by searching from the point cloud correspondences in the image (P2F), instead of matching features from the image to points. This formulation causes an overhead in computation but is correctly handled by considering a compressed version of the \ac{sfm} model and by implementing end-conditions and rejection cases in their algorithm.
			
			\citet{Sattler2011} consider the original features to points correspondences scheme by~\citep{Irschara2009} and introduce a Vocabulary-based Prioritized Search (VPS) inspired by BoF matching method. Subsequent works by the same authors~\citep{Sattler2012} augment the VPS framework with the points to features matching P2F~\citep{Li2010}. \citet{Li2012} show that the class of methods introduced in~\citep{Irschara2009,Li2010} can deal with large environment. Authors augment the P2F matching with hypothesis of co-occurrence of 3D points present in a close neighbourhood. Based on similar spatial observation, \citet{Sattler2015} consider visibility graph to reject wrong matchings. \citet{Heisterklaus2014} introduce MPEG compression for visual document in order to speed-up the system. In the work described in~\citep{Donoser2014}, authors use the descriptor redundancy associated to 3D points to train random ferns on the top of each points. F2P matching time requirement is by the fact greatly reduced. 
			
			Works from~\citep{Middelberg2014,Lynen2015} tackle the problem of \ac{vbl} embedded in a mobile device with limited memory storage and computational power. To achieve real-time performances, authors in~\citep{Middelberg2014} produce a very light 3D model to track the mobile camera in an urban environment. They send at regular interval key-frames to a server that is in charge of computing the global pose of the camera regarding a pre-produced point cloud. Aligning a light relative point cloud reconstructed with \ac{sfm} to a bigger one have also been investigated in~\citep{Lu2015}. \citet{Svarm2014} consider the problem of \ac{vbl} with F2P matching as a combinatorial optimization problem and design a fast outliers rejection scheme. This promising work have been improved through~\citep{Zeisl2015,Svarm2016} contributions.
			
			State of the art \ac{vbl} methods based on \ac{sfm} are dominated by techniques combining previously mentioned improvements~\citep{Sattler2016a}. Recent work by \citet{Feng2016a} reduce drastically the computational power requirement by considering fast point extractor and binary descriptors combined with an efficient similarity research. Authors show an order of magnitude in time reduction without any pose estimation performances deterioration.
			%\citep{Chen2016} A lire about end-user issues
		
		\paragraph{Features to Points pose estimation}
			F2P provides correspondences between 2D pixels and 3D colourized points. Defined by \citet{Hartley2003}, perspective-$n$-point (P$n$P) formulation is the most common tool to recover the absolute camera pose according to the point cloud reconstructed by \ac{sfm}.
			
			Embedded in a random consensus scheme (see \S\ref{par:ransac}), six correspondences between the image and the 3D model are sufficient to retrieve the pose, if we have no information about the intrinsic parameters of the camera~\citep{Donoser2014,Li2010,Li2010,Heisterklaus2014}. This formulation is known as P6P and can be solved with Direct Linear Transformation (DLT \citep{Hartley2003}).
			
			In particular cases, three correspondences between the image and the model are sufficient (P3P pose computation problem). Especially, the pose estimation problem can be reduced to a P3P formulation if the intrinsic parameters of the camera are known~\citep{Irschara2009,Middelberg2014}, or if 3 or more \ac{dof} are fixed~\citep{Zeisl2015,Qu2016}. In those particular cases, P3P solver introduced by \citet{Kneip2011} is mostly used to recover the pose. 
		%Parler du truc dans \cite{Song2016}
												
	\subsection{Direct pose regression}
    	\label{subsec:pose_regression}
    	The last class of reviewed direct methods cast \ac{vbl} as a pose regression problem. Two different kinds of regressors are employed in the literature: regression forest and \ac{cnn}.
    	
		\paragraph{Regression forest}
			In the initial works by~\citet{Shotton2013}, authors encode, thanks to RGB-D data, the global position of each pixel associated to a known environment in a regression forest. At query time, a handful of pixels from a depth camera frame are processed into the regression forest. The multiple pose hypothesis obtained for each pixel is then optimized in a random consensus to regress the camera position and orientation. This method is fast and precise and can be used on texture-less data. However, the depth information associated to each pixel is needed and the authors have to train a specific forest for each 3D scene. This initial method have been improved in~\citep{Guzman-rivera2014}, where authors take in consideration several candidates for the final pose regression obtained by trained predictors. \citet{Valentin2015} introduce mixture of Gaussian to represent the uncertainty associated with the regression forest prediction and significantly improve the 6 \ac{dof} estimation by embedding this information within the full camera pose regression step. The regression forest have been replaced by Neural Network (NN) in~\citep{Massiceti2016}, bringing slightly better result at the cost of computational overhead. \citet{Meng2016} consider only RGB images at query time. The loss in precision is compensated by a post pose refinement step based on nearest neighbours search with sparse extracted SIFT features.
            
            Inspired by works presented above, \citet{Glocker2013} (extended version in~\citep{Glocker2015}) design a system based on regression ferns to quickly associate an RGB-D image to a binary feature. Ferns produce descriptor according to randomly initialized binary rules, and a look up table is maintained to directly associated image signature with 3D pose in the scene. Presented system is less precise that the one presented by~\citet{Shotton2013} but has the advantages of not relying on a heavy pre-processing step (i.e. the spawning of the regression forest). Along the same line, \citet{Cavallari} propose a new method based on pre-trained regression forest. This method permit to recover the pose of a RGB-D camera without prior knowledge about the 3D scene, more precisely than~\citet{Glocker2013,Glocker2015}.
			

		\paragraph{CNN regressors}
			\label{para:cnn_regressor}
			Introduced in 2015 by \citet{Kendall2015}, PoseNet consists of the fine-tuning of a \ac{cnn} for the task of localization. The network is trained upon a set of paired image/pose and automatically regress the 6 \ac{dof} pose of a camera that acquired a colour image. The pose obtained through this method is not as accurate as the pose obtained with ``classical'' direct methods \citep{Feng2016a,Sattler2016a} but provide great tolerance to changes in scale and appearance. Compared to regression forest~\citep{Valentin2015}, \ac{cnn} seems more appropriate to handle large environment and does not rely on depth information.
			
			Recent improvement have been proposed by the original authors~\citep{Kendall2016} to integrate an uncertainty estimation in the regression process. \citet{Liu2016} integrate this \ac{cnn} architecture with only depth map information for recovering the pose of a camera in complete obscurity. The work by Walch et al.~\citep{Walch2016mastersThesis,Walch2016a} present a combination of a PoseNet~\citep{Kendall2015} with a \ac{lstm} units plugged at the output of the network in order to encode stronger spatial information from the image. This combination slightly improves the precision of the system. \citet{Jia2016} highlight the limited number of training example available for \ac{cnn} pose regressors. Though the learning transfer seems to be efficient~\citep{Kendall2015}, authors propose a new method to gather supplementary image/pose pairs for the fine-tuning step. They generate artificial images from a dense point cloud model obtained by \ac{sfm} thanks to a rendering software. Computer graphics shaders effects are added on some rendered views for simulating various illuminations. \citet{Contreras2017} exploit this CNN architecture in order to create a fixed size map that can be improved by adding new trajectories. Authors were able to reduce the original size of the CNN by factor of three while maintaining similar localization performances on indoor scenes. Recent contribution~\citep{Kendall2017} investigate new loss-functions for the training phase of the \ac{cnn}, mimicking the philosophy used in multi-view geometry standard systems~\citep{Hartley2003}.
			
			Differently, recent work from~\citet{Weyand2016} consider the localization problem as a classification task. They perform a worldwide training on 126M images categorized into 26k places across the globe. According to a given image a \ac{cnn}, named PlaNET, estimates a map of probable location for the query. Localization of multiples photos taken from a common album can be performed by augmenting the original network with a \ac{lstm} layer. \citet{Vo2017} push further the study of such a neural network and conclude that the features extracted from layers of PlaNET are more discriminative to determine the location of an input image that the CNN classifier itself. By extracting features instead of using a classification algorithm, their contribution is closer to the original world-wide localization method IM2GPS~\citep{Hays2008}.