\section{Related work}

\subsection{Image-based localisation}

\citet{Sattler2016a} have designed a state-of-the-art camera localisation system where 2D hand-crafted features from the query image are matched to a large 3D point clouds created by Structure from Motion (SfM). Another successful approach has been presented in~\citep{Sattler2017, Sattler2017a,Sarlin2018a, Sarlin2018} with a coarse to fine localisation pipeline by initial image indexing followed by feature registration on a local 3D model. In~\citep{Taira2018}, the hand-crafted features usually used for image matching are replaced by dense matching using features block for pre-trained CNN with successive geometric verification steps using a complete 3D model of an indoor building. In~\citep{Schonberger2017a}, authors use, in combination with 3D geometry, semantic labelling of the scene to perform outdoor localisation at large scale. In our proposal, we adopt the coarse to fine localisation strategy while limiting the data required during the pose request to images only.

Learning approaches for camera localisation have also been considered since early work from~\citep{Shotton2013} that uses regression forest at pixel level for fast pose estimation. \citet{Cavallari2018} extended this work by reusing the forest structure for fast adaptation to unknown scene. Pose regression CNN-based methods~\citep{Kendall2015, Kendall2016, Kendall2017a, Walch2016a, Saha2018} and more recently coordinates regression method~\citep{Brachmann2017,Brachmann2017b, Li2018} are also well studied topics and provide compact localisation system relying on images only. We do not design our system as a direct image to pose regression method, as this approach cannot be generalised and needs specific training and model for each new environment. Closest work to our is a method called Relocnet~\citep{Purkait2018}, where authors use a two-step localisation approach consisting of a first pose estimation by CBIR followed by a relative pose estimation between two images with a CNN. By learning relative information, Relocnet can be used in various environment without specific training for each scenes.

\subsection{Depth from monocular image for localisation}
Modern neural networks architectures can provide reliable estimation of the depth associated to monocular image in a simple and fast manner~\citep{Eigen2014, Godard2017, Mahjourian2018}. This ability of neural networks has been used in~\citep{Tateno2017} to recover the absolute scale in a SLAM mapping system. \citet{Loo2019} use the depth estimation produced by a CNN to improve a visual odometry algorithm by reducing the incertitude related to the projected 3D points. In~\citep{Piasco2019}, authors use the depth map generated from monocular images as stable features across season changes within a CBIR localisation framework. As in~\citep{Piasco2019a}, we use the depth information obtained by a neural network to project 2D points in 3D for 6-DoF pose estimation and for modeling the geometry of multiples environment within a common model.